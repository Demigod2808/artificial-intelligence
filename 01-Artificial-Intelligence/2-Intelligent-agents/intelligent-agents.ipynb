{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Intelligent-Agents\" data-toc-modified-id=\"Intelligent-Agents-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intelligent Agents</a></div><div class=\"lev2 toc-item\"><a href=\"#Agents-and-Environments\" data-toc-modified-id=\"Agents-and-Environments-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Agents and Environments</a></div><div class=\"lev2 toc-item\"><a href=\"#Good-Behavior:-The-Concept-of-Rationality\" data-toc-modified-id=\"Good-Behavior:-The-Concept-of-Rationality-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Good Behavior: The Concept of Rationality</a></div><div class=\"lev3 toc-item\"><a href=\"#Rationality\" data-toc-modified-id=\"Rationality-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Rationality</a></div><div class=\"lev3 toc-item\"><a href=\"#Omniscience,-learning,-and-autonomy\" data-toc-modified-id=\"Omniscience,-learning,-and-autonomy-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Omniscience, learning, and autonomy</a></div><div class=\"lev2 toc-item\"><a href=\"#Key-Points\" data-toc-modified-id=\"Key-Points-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Key Points</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents and Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An **agent** is anything that can be viewed as perceiving its **environment** through **sensors** and acting upon that environment through **actuators**.\n",
    "\n",
    "![](https://i.imgur.com/x79uGFG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A human agent has eyes, ears, and other organs for sensors and hands, legs, vocal tract of actuators.\n",
    "- A robotic agent might have cameras and infrared range finders for sensors and various motors for actuators.\n",
    "- A software agent receives keystrokes, file contents, and network packets as sensory inputs and acts on environment by displaying on the screen, writing files, etc.\n",
    "\n",
    "- An agent's **percept sequence** is the complete history of everything that agent has ever perceived.\n",
    ">An agent's choice of action at any given instant can depend on the entire percept sequence observed to date, but not on anything it hasn't perceived.\n",
    "\n",
    "- Mathematically speaking, we say that an agent's behavior is described by the **agent function** that maps any given percept sequence to an action.\n",
    "- *Internally,* the agent function for an artificial agent will be implemented by an **agent program**. It is important to keep these two ideas distinct.\n",
    ">**The agent function** is an abstract mathematical description, **the agent program** is a concrete implementation, running within some physical system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Behavior: The Concept of Rationality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **rational agent** is one that does the right thing—conceptually speaking, every entry in the table for the agent function is filled out correctly. Obviously, doing the right thing is better than doing the wrong thing, but what does it mean to do the right thing?\n",
    "\n",
    "- When an agent is plunked down in an environment, it generates a sequence of actions according to the percepts it receives. This sequence of actions causes the environment to go through a sequence of states. If the sequence is desirable, then the agent has performed well. This notion of desirability is captured by a **performance measure** that evaluates any given sequence of environment states.\n",
    "\n",
    ">As a generall rule, it is better to design performance measures according to what one actually wants in the environment, rather than according to how one thinks the agent should behave.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rationality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rationality at any given time depends on four things:\n",
    "    - The performance measure that defines the criterion of success.\n",
    "    - The agent's prior knowledge of the environment.\n",
    "    - The actions that the agent can perform.\n",
    "    - The agent's percept sequence to date.\n",
    "    \n",
    "- This leads to a **definition of a rational agent**:\n",
    ">For each possible percept sequence, a rational agent should select an action that is ex-\n",
    "pected to maximize its performance measure, given the evidence provided by the percept\n",
    "sequence and whatever built-in knowledge the agent has.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omniscience, learning, and autonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An **agent** is something that perceives and acts in an environment. The agent function for an agent specifies the action taken by the agent in response to any percept sequence.\n",
    "- The **performance measure** evaluates the behavior of the agent in an environment. A rational agent acts so as to maximize the expected value of the performance measure, given the percept sequence it has seen so far.\n",
    "- A **task environment** specification includes the performance measure, the external environment, the actuators, and the sensors. In designing an agent, the first step must always be to specify the task environment as fully as possible.\n",
    "- Task environments vary along several significant dimensions. They can be fully or partially observable, single-agent or multiagent, deterministic or stochastic, episodic or sequential, static or dynamic, discrete or continuous, and known or unknown.\n",
    "- The **agent program** implements the agent function. There exists a variety of basic agent-program designs reflecting the kind of information made explicit and used in the decision process. The designs vary in efficiency, compactness, and flexibility. The appropriate design of the agent program depends on the nature of the environment.\n",
    "- **Simple reflex agents** respond directly to percepts, whereas **model-based reflex agents** maintain internal state to track aspects of the world that are not evident in the current percept. **Goal-based agents** act to achieve their goals, and **utility-based agents** try to maximize their own expected “happiness.”\n",
    "- All agents can improve their performance through **learning**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
