{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Solving-Problems-By-Searching\" data-toc-modified-id=\"Solving-Problems-By-Searching-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Solving Problems By Searching</a></div><div class=\"lev2 toc-item\"><a href=\"#Question\" data-toc-modified-id=\"Question-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Question</a></div><div class=\"lev2 toc-item\"><a href=\"#Application\" data-toc-modified-id=\"Application-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Application</a></div><div class=\"lev2 toc-item\"><a href=\"#Beyond-reflex\" data-toc-modified-id=\"Beyond-reflex-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Beyond reflex</a></div><div class=\"lev2 toc-item\"><a href=\"#Tree-Search\" data-toc-modified-id=\"Tree-Search-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Tree Search</a></div><div class=\"lev2 toc-item\"><a href=\"#Backtracking-Search\" data-toc-modified-id=\"Backtracking-Search-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Backtracking Search</a></div><div class=\"lev2 toc-item\"><a href=\"#Depth-first-search\" data-toc-modified-id=\"Depth-first-search-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Depth-first search</a></div><div class=\"lev2 toc-item\"><a href=\"#Breadth-first-search\" data-toc-modified-id=\"Breadth-first-search-17\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Breadth-first search</a></div><div class=\"lev2 toc-item\"><a href=\"#DFS-with-iterative-deepening\" data-toc-modified-id=\"DFS-with-iterative-deepening-18\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>DFS with iterative deepening</a></div><div class=\"lev2 toc-item\"><a href=\"#Tree-Search-Algorithms-Summary\" data-toc-modified-id=\"Tree-Search-Algorithms-Summary-19\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Tree Search Algorithms Summary</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Problems By Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Problem-solving agent** uses **atomic** representations - that is, states of the world are considered as wholes, with no internal structure visible to the problem solving algorithms.\n",
    "- **Goal-based agents** aka **Planning agents** use more advanced **factored** or **structured** representations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](http://i.imgur.com/Y46A2uk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you solve this problem, try to think about how you did it. You probably simulated the scenario in your head, trying to send the farmer over with the goat, observing the consequences. If nothing got eaten, you might continue with the next action. Otherwise, you undo that move and try something else.\n",
    "- How can we get a machine to do this automatically? One of the things we need is a systematic approach that considers all the possibilities. We will see that search problems define the possibilities, and search algorithms explore these possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/0KJxDFw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Route finding is perhaps the most canonical example of a search problem. We are given as the input  a map, a source point and a destination point. The goal is to output a sequence of actions (e.g., go straight, turn left, or turn right) that will take us from the source to the destination.\n",
    "- We might evaluate action sequences based on an objective (distance, time, or pleasantness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/rovS6up.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In robot motion planning, the goal is get a robot to move from one position/pose to another. The desired output trajectory consists of individual actions, each action corresponding to moving or rotating the joints by a small amount.\n",
    "- Again, we might evaluate action sequences based on various resources like time or energy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond reflex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/ja8Gx0b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reflex-based models (e.g., linear predictors and neural networks) output either a $-1$ or $+1$ (for binary classification) or a real number (for regression).\n",
    "- While reflex-based models were appropriate for some applications such as sentiment classification or spam filtering, the applications we will look at today, such as solving puzzles, demand more.\n",
    "- To tackle these new problems, we will introduce search problems, our first instance of a **state-based model**.\n",
    "- In a search problem, in a sense, we are still building a predictor $f$ which takes an input $x$, but $f$ will now return an entire action sequence, not just a single action. Of course you should object: can't I just apply a reflex model iteratively to generate a sequence? While that is true, the search problems that we're trying to solve importantly require reasoning about the consequences of the entire action sequence, and cannot be tackled by myopically predicting one action at a time.\n",
    "- Tangent: Of course, saying \"cannot\" is a bit strong, since sometimes a search problem can be solved by a reflex-based model. You could have a massive lookup table that told you what the best action to take for any given situation. (It is interesting to think of this as a time/memory tradeoff where reflex-based models are performing an implicit kind of caching.) Going on a further tangent, one can even imagine compiling a state-based model into a reflex-based model; if you're walking around Stanford for the first time, you might have to really plan things out, but eventually it kind of becomes reflex.\n",
    "- There are many real-world examples of this paradigm, which we will describe next. For each example, the key is to decompose the output solution into a sequence of primitive actions. In addition, we need to think about how to evaluate different possible outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tree Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/5wdJ2Cj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/99kLDnm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/nDgbubM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will build what we will call a **search tree**. The root of the tree is the start state $S_{start}$, and the leaves are the end states ( $IsEnd(s)$ is true). Each edge leaving a node $s$ corresponds to a possible action $a\\in Actions(s)$  that could be performed in state $s$ . The edge is labeled with the action and its cost, written $a:Cost(s, a)$ . The action leads deterministically to the successor state $Succ(s, a)$, represented by the child node.\n",
    "\n",
    "- In summary, each root-to-leaf path represents a possible action sequence, and the sum of the costs of the edges is the cost of that path. The goal is to find the root-to-leaf path that has the minimum cost.\n",
    "- Note that in code, we usually do not build the search tree as a concrete data structure. The search tree is used merely to visualize the computation of the search algorithms and study the structure of the search problem.\n",
    "- For the boat crossing example, we have assumed each action (a safe river crossing) costs 1 unit of time. Invalid actions (ones that result in an eating event) cost $\\infty $ and the successor is marked in red. We disallow actions that return us to an earlier configuration. The green nodes are the end states. From this search tree, we see that there are exactly two solutions, each of which has a total cost of 7 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/Isuy8rO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's consider another problem and practice modeling it as a search problem. Recall that this means specifying precisely what the states, actions, goals, costs, and successors are.\n",
    "- To avoid the ambiguity of natural language, we will do this directly in code, where we define a **SearchProblem** class and implement the methods: **startState**, **isEnd** and **succAndCost**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtracking Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's put modeling aside and suppose we are handed a search problem. How do we construct an algorithm for finding a minimum cost path (not necessarily unique)?\n",
    "- We will start with backtracking search, the simplest algorithm which just tries all paths. The algorithm is called recursively on the current state $s$  and the path path leading up to that state. If we have reached a goal, then we can update the minimum cost path with the current path. Otherwise, we consider all possible actions $a$ from state $s$ , and recursively search each of the possibilities.\n",
    "- Graphically, backtracking search performs a depth-first traversal of the search tree. What is the time and memory complexity of this algorithm?\n",
    "- To get a simple characterization, assume that the search tree has maximum depth $D$(each path consists of  $D$ actions/edges) and that there are $b$ available actions per state (the branching factor is $b$).\n",
    "- It is easy to see that backtracking search only requires $O(D)$  memory (to maintain the stack for the recurrence), which is as good as it gets.\n",
    "- However, the running time is proportional to the number of nodes in the tree, since the algorithm needs to check each of them. The number of nodes is $1 + b + b^2 + \\cdots + b^D = \\frac{b^{D+1} - 1}{b-1} = O(b^D)$. Note that the total number of nodes in the search tree is on the same order as the number of leaves, so the cost is always dominated by the last level.\n",
    "- In general, there might not be a finite upper bound on the depth of a search tree. In this case, there are two options: (i) we can simply cap the maximum depth and give up after a certain point or (ii) we can disallow visits to the same state.\n",
    "\n",
    "![](https://i.imgur.com/Eeq9Uzr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth-first search\n",
    "\n",
    "Depth-first search always expands the deepest node in the current frontier of the search tree.\n",
    "The progress of the search is illustrated in Figure 3.16. The search proceeds immediately\n",
    "to the deepest level of the search tree, where the nodes have no successors. As those nodes\n",
    "are expanded, they are dropped from the frontier, so then the search “backs up” to the next\n",
    "deepest node that still has unexplored successors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/lddQsV4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Backtracking search will always work (i.e., find a minimum cost path), but there are cases where we can do it faster. But in order to do that, we need some additional assumptions — there is no free lunch.\n",
    "- Suppose we make the assumption that all the action costs are zero. In other words, all we care about is finding a valid action sequence that reaches the goal. Any such sequence will have the minimum cost: zero.\n",
    "- In this case, we can just modify backtracking search to not keep track of costs and then stop searching as soon as we reach a goal. The resulting algorithm is depth-first search (DFS), which should be familiar to you. The worst time and space complexity are of the same order as backtracking search. In particular, if there is no path to an end state, then we have to search the entire tree.\n",
    "- However, if there are many ways to reach the end state, then we can stop much earlier without exhausting the search tree. So DFS is great when there are an abundance of solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breadth-first search\n",
    "![](https://i.imgur.com/UbcZp2E.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Breadth-first search is a simple strategy in which the root node is expanded first, then all the successors of the root node are expanded next, then their successors, and so on. In general, all the nodes are expanded at a given depth in the search tree before any nodes at the next level are expanded.\n",
    "\n",
    "- **Breadth-first search (BFS)**, which should also be familiar, makes a less stringent assumption, that all the action costs are the same non-negative number. This effectively means that all the paths of a given length have the same cost.\n",
    "- BFS maintains a queue of states to be explored. It pops a state off the queue, then pushes its successors back on the queue.\n",
    "- BFS will search all the paths consisting of one edge, two edges, three edges, etc., until it finds a path that reaches a end state. So if the solution has $d$ actions, then we only need to explore $O(b^d)$ nodes, thus taking that much time.\n",
    "- However, a potential show-stopper is that BFS also requires $O(b^d)$  space since the queue must contain all the nodes of a given level of the search tree. Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/0NCXt5n.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFS with iterative deepening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/lV3MJFS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yes, we can do better with a trick called **iterative deepening**. The idea is to modify DFS to make it stop after reaching a certain depth. Therefore, we can invoke this modified DFS to find whether a valid path exists with at most $d$ edges, which as discussed earlier takes $O(d)$ space and $O(b^d)$ time.\n",
    "- Now the trick is simply to invoke this modified DFS with cutoff depths of $1, 2, 3, \\dots$ until we find a solution or give up. This algorithm is called DFS with iterative deepening (DFS-ID). In this manner, we are guaranteed optimality when all action costs are equal (like BFS), but we enjoy the parsimonious space requirements of DFS.\n",
    "- One might worry that we are doing a lot of work, searching some nodes many times. However, keep in mind that both the number of leaves and the number of nodes in a search tree is $O(b^d)$  so asymptotically DFS with iterative deepening is the same time complexity as BFS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Search Algorithms Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/tRPZ0FF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is a summary of all the tree search algorithms, the assumptions on the action costs, and the space and time complexities.\n",
    "- The take-away is that we can't avoid the exponential time complexity, but we can certainly have linear space complexity. Space is in some sense the more critical dimension in search problems. Memory cannot magically grow, whereas time \"grows\" just by running an algorithm for a longer period of time, or even by parallelizing it across multiple machines (e.g., where each processor gets its own subtree to search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
